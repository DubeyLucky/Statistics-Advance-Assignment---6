{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7283722d",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f439fd",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a statistical method used to compare the means of three or more groups to determine whether there are statistically significant differences between them. However, ANOVA relies on several assumptions for its validity. Here are the key assumptions:\n",
    "\n",
    "1. **Independence**: The observations within each group must be independent of each other. This means that the data points within one group should not be influenced by or correlated with the data points in another group. Violations of independence could occur in clustered or correlated data, such as repeated measures or nested designs, where observations within the same group are more similar to each other than to observations in other groups.\n",
    "\n",
    "2. **Normality**: The data within each group should be approximately normally distributed. While ANOVA is robust to moderate departures from normality, severe departures can lead to inflated Type I error rates (false positives) or reduced power. Violations of normality may occur when the data are highly skewed or have heavy tails.\n",
    "\n",
    "3. **Homogeneity of Variance (Homoscedasticity)**: The variances of the groups should be approximately equal. Homogeneity of variance ensures that the groups have similar dispersion or spread of scores around their respective group means. Violations of homogeneity of variance, known as heteroscedasticity, can lead to biased estimates of group means and inflated Type I error rates. This assumption is particularly important because ANOVA is sensitive to differences in variance between groups.\n",
    "\n",
    "4. **Independence of Errors**: The residuals (the differences between observed and predicted values) should be independent of each other and have constant variance across all levels of the independent variable. Violations of independence of errors can occur when there is autocorrelation or serial correlation in the data, leading to biased estimates of error terms and incorrect standard errors.\n",
    "\n",
    "Examples of violations of these assumptions that could impact the validity of ANOVA results include:\n",
    "\n",
    "- Independence: In a repeated measures design where the same subjects are measured over time, observations within the same subject are likely to be correlated, violating the independence assumption.\n",
    "- Normality: In skewed or heavily tailed distributions, the assumption of normality may be violated, leading to inaccurate inference.\n",
    "- Homogeneity of Variance: If one group has substantially larger variances than the others, ANOVA may incorrectly conclude that there are significant differences between groups when the differences are actually due to differences in variability.\n",
    "- Independence of Errors: In time series data or spatial data, observations may be correlated over time or space, violating the assumption of independent errors and leading to incorrect inferences.\n",
    "\n",
    "It's important to assess these assumptions before interpreting the results of ANOVA and consider alternative approaches if the assumptions are violated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f043e",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cd05fd",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a statistical technique used to compare means between two or more groups. There are three main types of ANOVA:\n",
    "\n",
    "1. **One-Way ANOVA**:\n",
    "   - **Usage**: One-Way ANOVA is used when comparing the means of three or more independent groups on a single continuous dependent variable.\n",
    "   - **Example**: Suppose we want to compare the effectiveness of three different teaching methods (A, B, and C) on student exam scores. Each teaching method represents a separate group, and the exam scores are the continuous dependent variable. One-Way ANOVA can determine if there are significant differences in mean exam scores between the three teaching methods.\n",
    "\n",
    "2. **Two-Way ANOVA**:\n",
    "   - **Usage**: Two-Way ANOVA is an extension of One-Way ANOVA that allows for the simultaneous comparison of the effects of two categorical independent variables (factors) on a single continuous dependent variable.\n",
    "   - **Example**: Consider a study investigating the effects of both gender and treatment type on patient outcomes. Gender (male or female) and treatment type (treatment A or treatment B) are two independent variables, and patient outcomes (e.g., recovery time) are the dependent variable. Two-Way ANOVA can determine if there are significant main effects of gender and treatment type, as well as any interaction effect between them.\n",
    "\n",
    "3. **Repeated Measures ANOVA**:\n",
    "   - **Usage**: Repeated Measures ANOVA is used when comparing means across three or more related groups, where the same subjects are measured under different conditions or at multiple time points.\n",
    "   - **Example**: Suppose we want to investigate the effect of a new drug on blood pressure levels over time. Blood pressure measurements are taken from the same group of individuals at baseline, one month, and three months after starting the drug treatment. Repeated Measures ANOVA can determine if there are significant changes in mean blood pressure levels over time due to the drug treatment.\n",
    "\n",
    "In summary:\n",
    "- Use One-Way ANOVA when comparing means across three or more independent groups on a single continuous dependent variable.\n",
    "- Use Two-Way ANOVA when examining the effects of two categorical independent variables on a single continuous dependent variable, or when assessing interaction effects between these variables.\n",
    "- Use Repeated Measures ANOVA when comparing means across three or more related groups measured under different conditions or at multiple time points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf68be",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97b2421",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA refers to the decomposition of the total variance observed in the data into different components that can be attributed to different sources or factors. Understanding this concept is crucial because it provides insights into the sources of variation in the data and helps in interpreting the results of the ANOVA analysis. The partitioning of variance in ANOVA typically involves three main components:\n",
    "\n",
    "1. **Between-Group Variance (or Treatment Variance)**:\n",
    "   - This component of variance represents the variability between the group means. It reflects the differences in the dependent variable (e.g., means, variances) across the different levels of the independent variable (or treatment).\n",
    "   - The larger the between-group variance relative to the within-group variance, the more evidence there is for differences between the groups.\n",
    "\n",
    "2. **Within-Group Variance (or Error Variance)**:\n",
    "   - This component of variance represents the variability within each group. It reflects the variability in the dependent variable that is not accounted for by the differences between the group means.\n",
    "   - The within-group variance serves as a measure of the random variability or noise in the data.\n",
    "\n",
    "3. **Total Variance**:\n",
    "   - This is the overall variability observed in the data, regardless of the grouping factor. It is the sum of the between-group and within-group variances.\n",
    "   - Total variance represents the variability in the dependent variable across all observations.\n",
    "\n",
    "Understanding the partitioning of variance is important for several reasons:\n",
    "\n",
    "- **Interpretation of Results**: By understanding how the total variance is divided into between-group and within-group components, researchers can better interpret the significance of the observed differences between groups.\n",
    "  \n",
    "- **Assessment of Effect Size**: The ratio of between-group variance to within-group variance (known as the F-statistic in ANOVA) provides a measure of effect size, indicating the magnitude of differences between groups relative to the random variability in the data.\n",
    "  \n",
    "- **Identification of Sources of Variation**: Partitioning of variance helps identify which factors or variables contribute the most to the overall variability in the dependent variable. This can guide further investigation or experimental design.\n",
    "\n",
    "- **Model Evaluation**: Understanding the partitioning of variance aids in evaluating the adequacy of the ANOVA model and the appropriateness of the assumptions underlying the analysis.\n",
    "\n",
    "In summary, the partitioning of variance provides valuable insights into the structure of the data and the underlying relationships between variables, facilitating meaningful interpretation and inference in ANOVA analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf57613",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63414a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 36.8\n",
      "Explained Sum of Squares (SSE): 26.133333333333326\n",
      "Residual Sum of Squares (SSR): 10.666666666666671\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data (dependent variable)\n",
    "data = [10, 12, 15, 14, 18]  # Example data for illustration\n",
    "\n",
    "# Calculate overall mean\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "# Calculate Total Sum of Squares (SST)\n",
    "SST = np.sum((data - overall_mean) ** 2)\n",
    "\n",
    "# Example treatment or group means\n",
    "group_means = [np.mean([10, 12]), np.mean([15, 14, 18])]  # Example group means for illustration\n",
    "\n",
    "# Calculate Explained Sum of Squares (SSE)\n",
    "SSE = np.sum([len(group) * (group_mean - overall_mean) ** 2 for group, group_mean in zip([data[:2], data[2:]], group_means)])\n",
    "\n",
    "# Calculate Residual Sum of Squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "# Print the results\n",
    "print(\"Total Sum of Squares (SST):\", SST)\n",
    "print(\"Explained Sum of Squares (SSE):\", SSE)\n",
    "print(\"Residual Sum of Squares (SSR):\", SSR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c43bb3",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49804fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.238\n",
      "Model:                            OLS   Adj. R-squared:                 -0.333\n",
      "Method:                 Least Squares   F-statistic:                    0.4167\n",
      "Date:                Tue, 27 Feb 2024   Prob (F-statistic):              0.751\n",
      "Time:                        15:05:06   Log-Likelihood:                -29.772\n",
      "No. Observations:                   8   AIC:                             67.54\n",
      "Df Residuals:                       4   BIC:                             67.86\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                20.0000     10.000      2.000      0.116      -7.764      47.764\n",
      "C(A)[T.A2]               10.0000     14.142      0.707      0.519     -29.265      49.265\n",
      "C(B)[T.B2]                5.0000     14.142      0.354      0.742     -34.265      44.265\n",
      "C(A)[T.A2]:C(B)[T.B2] -2.487e-14     20.000  -1.24e-15      1.000     -55.529      55.529\n",
      "==============================================================================\n",
      "Omnibus:                        8.655   Durbin-Watson:                   0.500\n",
      "Prob(Omnibus):                  0.013   Jarque-Bera (JB):                1.333\n",
      "Skew:                          -0.000   Prob(JB):                        0.513\n",
      "Kurtosis:                       1.000   Cond. No.                         6.85\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Main Effects:\n",
      "C(A)[T.A2]    10.0\n",
      "C(B)[T.B2]     5.0\n",
      "dtype: float64\n",
      "Interaction Effect:\n",
      "-2.4868995751603507e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py:1736: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=8\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data\n",
    "data = {\n",
    "    'A': ['A1', 'A1', 'A2', 'A2', 'A1', 'A1', 'A2', 'A2'],\n",
    "    'B': ['B1', 'B2', 'B1', 'B2', 'B1', 'B2', 'B1', 'B2'],\n",
    "    'Y': [10, 15, 20, 25, 30, 35, 40, 45]\n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit two-way ANOVA model\n",
    "model = ols('Y ~ C(A) + C(B) + C(A):C(B)', data=df).fit()\n",
    "\n",
    "# Print ANOVA table\n",
    "print(model.summary())\n",
    "\n",
    "# Extract main effects\n",
    "main_effects = model.params[['C(A)[T.A2]', 'C(B)[T.B2]']]\n",
    "\n",
    "# Extract interaction effect\n",
    "interaction_effect = model.params['C(A)[T.A2]:C(B)[T.B2]']\n",
    "\n",
    "print(\"Main Effects:\")\n",
    "print(main_effects)\n",
    "print(\"Interaction Effect:\")\n",
    "print(interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0240d058",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44792bbc",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the F-statistic tests the null hypothesis that the means of the groups are equal against the alternative hypothesis that at least one group mean is different from the others. The p-value associated with the F-statistic indicates the probability of obtaining the observed F-statistic or more extreme results if the null hypothesis were true.\n",
    "\n",
    "Given an F-statistic of 5.23 and a p-value of 0.02:\n",
    "- If the significance level (α) is set to 0.05, we compare the p-value (0.02) to α.\n",
    "- Since the p-value (0.02) is less than the significance level (0.05), we reject the null hypothesis.\n",
    "- Therefore, we conclude that there are statistically significant differences between the groups.\n",
    "\n",
    "Interpretation:\n",
    "- The results suggest that there is evidence to reject the null hypothesis of equal group means in favor of the alternative hypothesis that at least one group mean is different.\n",
    "- In practical terms, this means that there are likely differences in the dependent variable (e.g., means, variances) across the groups being compared.\n",
    "- However, the ANOVA does not tell us which specific groups differ from each other. Post-hoc tests, such as Tukey's HSD or Bonferroni correction, can be conducted to determine pairwise differences between groups.\n",
    "\n",
    "In summary, with an F-statistic of 5.23 and a p-value of 0.02, we can conclude that there are statistically significant differences between the groups being compared in the one-way ANOVA analysis. Further analysis may be needed to determine the nature and direction of these differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddde5ae",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0c494e",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA requires careful consideration, as missing data can potentially bias the results and reduce the validity of the analysis. Here are some common approaches to handling missing data in repeated measures ANOVA, along with their potential consequences:\n",
    "\n",
    "1. **Complete Case Analysis (Listwise Deletion)**:\n",
    "   - This approach involves analyzing only the subjects with complete data for all time points.\n",
    "   - Pros:\n",
    "     - Simple to implement.\n",
    "     - Preserves the integrity of the observed data.\n",
    "   - Cons:\n",
    "     - Reduces sample size and statistical power, especially if missing data are not completely random.\n",
    "     - May introduce bias if missingness is related to the outcome or other variables.\n",
    "\n",
    "2. **Mean Imputation**:\n",
    "   - Missing values are replaced with the mean of the observed values for that variable.\n",
    "   - Pros:\n",
    "     - Preserves sample size and statistical power.\n",
    "   - Cons:\n",
    "     - Underestimates the variability in the data and can bias parameter estimates.\n",
    "     - Does not account for uncertainty introduced by imputation.\n",
    "\n",
    "3. **Last Observation Carried Forward (LOCF)**:\n",
    "   - Missing values are replaced with the value from the last observed time point for each subject.\n",
    "   - Pros:\n",
    "     - Preserves sample size and may be appropriate for certain types of data with monotonic trends.\n",
    "   - Cons:\n",
    "     - Assumes that missing values remain constant over time, which may not be realistic.\n",
    "     - Can bias estimates if there is systematic change over time.\n",
    "\n",
    "4. **Multiple Imputation**:\n",
    "   - Missing values are replaced with multiple plausible values based on observed data and statistical models.\n",
    "   - Pros:\n",
    "     - Preserves sample size and accounts for uncertainty introduced by imputation.\n",
    "     - Provides more accurate parameter estimates compared to single imputation methods.\n",
    "   - Cons:\n",
    "     - Requires more computational resources and statistical expertise.\n",
    "     - Results may vary depending on the chosen imputation model and assumptions.\n",
    "\n",
    "5. **Mixed Effects Models (REML)**:\n",
    "   - Mixed effects models can accommodate missing data under the missing at random (MAR) assumption.\n",
    "   - Pros:\n",
    "     - Utilizes all available data and provides unbiased parameter estimates under MAR.\n",
    "   - Cons:\n",
    "     - Assumes that missingness is related to observed data, which may not always hold.\n",
    "     - Requires careful modeling and consideration of missing data mechanisms.\n",
    "\n",
    "In summary, the choice of method for handling missing data in repeated measures ANOVA depends on the nature of the missingness, the underlying data distribution, and the research question. It is important to carefully consider the potential consequences of each approach and to perform sensitivity analyses to assess the robustness of the results. Additionally, reporting the method used for handling missing data and conducting sensitivity analyses can enhance the transparency and reproducibility of the study findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02421a98",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ffa0ce",
   "metadata": {},
   "source": [
    "Common post-hoc tests used after ANOVA include:\n",
    "\n",
    "1. **Tukey's Honestly Significant Difference (HSD)**:\n",
    "   - Tukey's HSD test is used to compare all possible pairs of group means following a significant ANOVA result.\n",
    "   - It controls the family-wise error rate, maintaining the overall Type I error rate at the desired level.\n",
    "   - It is suitable when you have multiple groups and want to identify which specific groups differ from each other.\n",
    "\n",
    "2. **Bonferroni Correction**:\n",
    "   - Bonferroni correction adjusts the significance level for multiple comparisons by dividing the desired overall significance level (e.g., α = 0.05) by the number of comparisons being made.\n",
    "   - It is more conservative than Tukey's HSD and controls the family-wise error rate, but it may be overly conservative and less powerful, especially when the number of comparisons is large.\n",
    "   - It is suitable when you have multiple pairwise comparisons to make and want to control the overall Type I error rate.\n",
    "\n",
    "3. **Sidak Correction**:\n",
    "   - Similar to Bonferroni correction, Sidak correction adjusts the significance level for multiple comparisons based on the number of comparisons being made.\n",
    "   - It is less conservative than Bonferroni correction and can be more powerful when the number of comparisons is relatively small.\n",
    "   - It is suitable when you have multiple pairwise comparisons and want to control the overall Type I error rate.\n",
    "\n",
    "4. **Dunnett's Test**:\n",
    "   - Dunnett's test compares all treatment groups to a control group or a reference group.\n",
    "   - It is useful when you have a control group and want to determine which treatment groups differ significantly from the control group.\n",
    "\n",
    "5. **Scheffe's Test**:\n",
    "   - Scheffe's test is a conservative post-hoc test that can be used for all possible pairwise comparisons among group means.\n",
    "   - It maintains the family-wise error rate for all possible comparisons, making it suitable when the number of comparisons is large and the groups have unequal sample sizes.\n",
    "\n",
    "Example situation:\n",
    "Suppose a researcher conducts an experiment to compare the effectiveness of three different treatments (Treatment A, B, and C) on reducing pain levels in patients. After conducting an ANOVA analysis, the researcher finds a significant overall effect of treatment. To further investigate which specific treatments differ from each other, the researcher would conduct post-hoc tests, such as Tukey's HSD or Bonferroni correction, to perform pairwise comparisons between the treatment groups. This would help identify which specific treatments are significantly different from each other in terms of their effect on pain reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3500f9e",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6473a80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 289.5453151162952\n",
      "p-value: 3.469146037673301e-51\n",
      "Reject the null hypothesis: There are significant differences between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Sample data (weight loss for each diet)\n",
    "diet_A = [3.2, 2.5, 4.0, 3.8, 2.9, 3.5, 4.2, 3.6, 2.8, 3.9,\n",
    "          3.1, 3.4, 3.7, 2.6, 4.1, 3.3, 3.0, 2.7, 3.8, 2.9,\n",
    "          3.3, 3.5, 2.8, 3.9, 3.6, 4.0, 3.1, 2.9, 3.7, 3.2,\n",
    "          2.5, 4.0, 3.8, 2.9, 3.5, 4.2, 3.6, 2.8, 3.9, 3.1,\n",
    "          3.4, 3.7, 2.6, 4.1, 3.3, 3.0, 2.7, 3.8, 2.9]\n",
    "\n",
    "diet_B = [2.0, 1.5, 2.8, 2.3, 1.9, 2.5, 2.6, 1.8, 2.1, 2.7,\n",
    "          1.7, 2.4, 2.9, 1.6, 2.2, 2.0, 2.3, 1.4, 2.6, 1.9,\n",
    "          2.2, 2.5, 1.8, 2.7, 1.9, 2.4, 2.0, 2.3, 2.8, 2.0,\n",
    "          1.5, 2.8, 2.3, 1.9, 2.5, 2.6, 1.8, 2.1, 2.7, 1.7,\n",
    "          2.4, 2.9, 1.6, 2.2, 2.0, 2.3, 1.4, 2.6, 1.9]\n",
    "\n",
    "diet_C = [1.0, 0.5, 1.8, 1.3, 0.9, 1.5, 1.6, 0.8, 1.1, 1.7,\n",
    "          0.7, 1.4, 1.9, 0.6, 1.2, 1.0, 1.3, 0.4, 1.6, 0.9,\n",
    "          1.2, 1.5, 0.8, 1.7, 0.9, 1.4, 1.0, 1.3, 1.8, 1.0,\n",
    "          0.5, 1.8, 1.3, 0.9, 1.5, 1.6, 0.8, 1.1, 1.7, 0.7,\n",
    "          1.4, 1.9, 0.6, 1.2, 1.0, 1.3, 0.4, 1.6, 0.9]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There are significant differences between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There are no significant differences between the mean weight loss of the three diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cffa6e1",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf780bb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 24\u001b[0m\n\u001b[0;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSoftware\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m              \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m13\u001b[39m]\n\u001b[0;32m     21\u001b[0m }\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Convert data to DataFrame\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Fit two-way ANOVA model\u001b[39;00m\n\u001b[0;32m     27\u001b[0m model \u001b[38;5;241m=\u001b[39m ols(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime ~ C(Software) + C(Experience) + C(Software):C(Experience)\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mdf)\u001b[38;5;241m.\u001b[39mfit()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data (time to complete task for each software program and experience level)\n",
    "data = {\n",
    "    'Software': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C',\n",
    "                 'A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C',\n",
    "                 'A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C',\n",
    "                 'A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "    'Experience': ['Novice', 'Experienced', 'Novice', 'Experienced', 'Novice', 'Experienced',\n",
    "                   'Novice', 'Experienced', 'Novice', 'Experienced', 'Novice', 'Experienced',\n",
    "                   'Novice', 'Experienced', 'Novice', 'Experienced', 'Novice', 'Experienced',\n",
    "                   'Novice', 'Experienced', 'Novice', 'Experienced', 'Novice', 'Experienced',\n",
    "                   'Novice', 'Experienced', 'Novice', 'Experienced', 'Novice', 'Experienced'],\n",
    "    'Time': [10, 8, 11, 9, 7, 10, 12, 9, 13,\n",
    "             11, 9, 10, 10, 8, 11, 12, 9, 13,\n",
    "             10, 8, 11, 9, 7, 10, 12, 9, 13,\n",
    "             11, 9, 10, 10, 8, 11, 12, 9, 13]\n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit two-way ANOVA model\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=df).fit()\n",
    "\n",
    "# Print ANOVA table\n",
    "print(sm.stats.anova_lm(model, typ=2))\n",
    "\n",
    "# Interpret the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6287288a",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a72a8435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -6.274481080767864\n",
      "p-value: 9.54723702808884e-09\n",
      "The difference in test scores between control and experimental groups is significant.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "import statsmodels.stats.multitest as smt\n",
    "\n",
    "# Sample data (test scores for control and experimental groups)\n",
    "control_scores = [78, 82, 75, 70, 85, 80, 72, 79, 81, 77,\n",
    "                  73, 76, 79, 83, 74, 78, 75, 80, 82, 76,\n",
    "                  71, 79, 84, 77, 80, 75, 78, 82, 76, 81,\n",
    "                  79, 83, 74, 78, 75, 80, 82, 76, 71, 79,\n",
    "                  84, 77, 80, 75, 78, 82, 76, 81, 79, 83]\n",
    "\n",
    "experimental_scores = [85, 80, 88, 82, 78, 86, 81, 79, 87, 83,\n",
    "                       79, 85, 80, 88, 82, 78, 86, 81, 79, 87,\n",
    "                       83, 79, 85, 80, 88, 82, 78, 86, 81, 79,\n",
    "                       87, 83, 79, 85, 80, 88, 82, 78, 86, 81,\n",
    "                       79, 87, 83, 79, 85, 80, 88, 82, 78, 86]\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# Print t-statistic and p-value\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check if results are significant\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The difference in test scores between control and experimental groups is significant.\")\n",
    "    # Perform post-hoc test (not applicable for two-sample t-test)\n",
    "else:\n",
    "    print(\"There is no significant difference in test scores between control and experimental groups.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087958a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
